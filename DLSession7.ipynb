{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to use Tensorflow to process text data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocabulary: A corpus i.e a collection of documents.  \n",
    "#### When we test the model and if the word is not present, then the model may specify as oov (out of vocabulary).\n",
    "#### \n",
    "#### First it assign the index number to each word. \n",
    "#### Then it assigns the index number to each sentence provided. \n",
    "#### If it does not recognize then it assigns the oov tokenizer. \n",
    "#### Padding is used (pad_sequences either as post or pre) to build the array of same size.  Paddig adds 0 to each row to make it as same length as the longest sentence. \n",
    "#### If one sentence is very very long then you use truncate in the preprocessing to optimize the processor. Otherwise padding will add too many zeros for remaining sentences causing performance issue.  \n",
    "#### Another option is to split the sentence into multiple sentences so that you dont need to add too many zeroes through padding. \n",
    "#### \n",
    "#### Cosine Similarity\n",
    "#### On a n-dimensional space, I represent each word with a number. And somehow I use the machine to create the word embedding to distinguish two words. \n",
    "#### \n",
    "#### Embeddings \n",
    "#### \n",
    "#### Word Embeddings: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = data['review']\n",
    "y_data = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    One of the other reviewers has mentioned that ...\n",
       "1    A wonderful little production. <br /><br />The...\n",
       "2    I thought this was a wonderful way to spend ti...\n",
       "3    Basically there's a family where a little boy ...\n",
       "4    Petter Mattei's \"Love in the Time of Money\" is...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49994    This is your typical junk comedy.<br /><br />T...\n",
       "49995    I thought this movie did a down right good job...\n",
       "49996    Bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    I am a Catholic taught in parochial elementary...\n",
       "49998    I'm going to have to disagree with the previou...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[-6:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X_data.replace({'<.*?>': \"\"}, regex=True)  # Remove html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X_data.replace({'[^A-Za-z]' : ' ' }, regex =True)  # Remove non-alphabetical characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X_data.apply(lambda review: review.lower()) # Convertt to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y_data.map({'positive': 1,  'negative': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split (X_data, y_data, test_size = 0.2, random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "tf.random.set_seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To encode text to int\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB=1000 # Limit the vocabulary to 1000 words\n",
    "EMBED_DIM = 32 # n-dimension for embedding Layer\n",
    "MAXLEN = 100  # Maximmum length of sentence\n",
    "\n",
    "# Our brain cannot visualize more than 3 dimensions. \n",
    "# Embedding layer will convert word into a number in a 32 dimensional space.\n",
    "## GloVe (google it...\n",
    "## Count Vectorization - It will use One Hot Encoding to assign number to bag of words. \n",
    "## Bag of Words - Vector Representation Example : You are counting the words. It's not going to do any other processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer(lower = True, \n",
    "                  num_words=VOCAB, \n",
    "                  oov_token='<OOV>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train and test data to list\n",
    "X_train_l = X_train.to_list()\n",
    "X_test_l = X_test.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "token.fit_on_texts(X_train_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s = token.texts_to_sequences(X_train_l)\n",
    "X_test_s = token.texts_to_sequences(X_test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s = pad_sequences(X_train_s, \n",
    "                          maxlen=MAXLEN,\n",
    "                          padding = 'post',\n",
    "                          truncating = 'post')\n",
    "# Here we are basically saying to pad the sequence to 100 words but truncate at the same time if any sentence is longer than 100 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_s = pad_sequences(X_test_s, \n",
    "                          maxlen=MAXLEN, # Do not forget to mention maxlen parameter for test dataset\n",
    "                          padding = 'post',\n",
    "                          truncating = 'post') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_s[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_s[58])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model.add(Embedding(VOCAB,\n",
    "                        EMBED_DIM,\n",
    "                        input_length = MAXLEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model.add(GlobalAveragePooling1D()) # Average Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model.add(Dense(128, activation = 'relu')) # Dense Layer - intermediate free connector layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model.add(Dense(1, activation = 'sigmoid')) # Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model.compile(optimizer = 'adam', \n",
    "                  loss = 'binary_crossentropy', \n",
    "                  metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 32)           32000     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 32)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               4224      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,353\n",
      "Trainable params: 36,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  100 is sentence length, 32 is dimension\n",
    "####  Embedding Param# 32,000 = 1000 words multiplied by 32 dimensions i.e. it will learn 32,000 \n",
    "####  Across each \n",
    "#### 33* 128 = 4224\n",
    "###  129* 1 = 129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.4820 - accuracy: 0.7603 - val_loss: 0.4305 - val_accuracy: 0.8012\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.4196 - accuracy: 0.8044 - val_loss: 0.4286 - val_accuracy: 0.8019\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.4163 - accuracy: 0.8055 - val_loss: 0.4320 - val_accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.4138 - accuracy: 0.8074 - val_loss: 0.4288 - val_accuracy: 0.8010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.4135 - accuracy: 0.8074 - val_loss: 0.4275 - val_accuracy: 0.8021\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.4113 - accuracy: 0.8084 - val_loss: 0.4313 - val_accuracy: 0.7964\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.4097 - accuracy: 0.8080 - val_loss: 0.4246 - val_accuracy: 0.8011\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.4068 - accuracy: 0.8088 - val_loss: 0.4245 - val_accuracy: 0.8022\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.4035 - accuracy: 0.8095 - val_loss: 0.4265 - val_accuracy: 0.8024\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.4007 - accuracy: 0.8090 - val_loss: 0.4214 - val_accuracy: 0.8022\n"
     ]
    }
   ],
   "source": [
    "result = emb_model.fit(X_train_s,\n",
    "                       y_train, \n",
    "                       validation_data=(X_test_s, y_test),\n",
    "                       epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reviews = [\"I bought this for my husband who plays the piano.  He is having a wonderful time playing these old hymns.  The music  is at times hard to read because we think the book was published for singing from more than playing from.  Great purchase though!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reviews = token.texts_to_sequences(new_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reviews = pad_sequences(new_reviews, \n",
    "                           maxlen = MAXLEN,\n",
    "                           padding = 'post',\n",
    "                           truncating = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10,   1,  11,  18,  60, 602,  36, 299,   2,   1,  25,   7, 261,\n",
       "          4, 394,  58, 395, 134, 157,   1,   2, 208,   7,  32, 209, 251,\n",
       "          6, 340,  87,  70, 103,   2, 269,  14,   1,  18,   1,  38,  53,\n",
       "         74, 395,  38,  82,   1, 155,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_reviews # the result shows that is has predicted positive sentiment as numbers are positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.981613]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.predict(new_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = emb_model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 32)\n"
     ]
    }
   ],
   "source": [
    "e = emb_model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in token.word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "vectors = io.open('vectors_emb_25Mar2023.tsv', 'w', encoding='utf-8') # Vectors\n",
    "metadata = io.open('metadata_emb_25Mar2023.tsv', 'w', encoding='utf-8') # Metadata\n",
    "for word_num in range(1, VOCAB):\n",
    "    word = reverse_word_index[word_num]\n",
    "    embeddings = weights[word_num]\n",
    "    metadata.write(word + \"\\n\")\n",
    "    vectors.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
    "vectors.close()\n",
    "metadata.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## They said Teddy bears are on sale\n",
    "## They said Teddy Roosevelt was a great president\n",
    "## In the above two sentences, first 3 words are same.  \n",
    "## Only when we go towards the end, we understand the context of the sentence\n",
    "##\n",
    "## To address this problem, we use bidirectional LSTM that will resolve the issue \n",
    "## by starting from the beginning and at the same time from the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidi_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidi_model.add(Embedding(VOCAB,\n",
    "                         EMBED_DIM,\n",
    "                         input_length = MAXLEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
